# MultiModal-SentimentAnalysis
## Interpreting User Sentiment in Instagram Posts: A Multimodal Deep Learning Approach

In the age of social media, Instagram serves as a prominent platform for users to express themselves through visual and textual content. However, deciphering the sentiments behind these posts, often laden with irony and cultural nuances, poses a significant challenge due to the intricate interplay between images and text. Being able to accurately classify the sentiment of an Instagram post would provide valuable insights for businesses seeking to gauge customer reception of their brand, or for sensitive users who wish to filter out negative posts from their feed. 

This repository introduces a multimodal deep learning approach aimed at interpreting user sentiment in Instagram posts by analyzing both visual and textual elements. Our proposed model integrates two parallel deep learning networks that process images along with their associated caption and comments. The conclusion of the postâ€™s overall sentiment would be deduced from a trainable weighted average of the two model predictions. We aim to develop a robust sentiment analysis model that can draw information from both the image post and associated caption to enhance user experience and engagement on Instagram across both commercial and personal spheres.


![image](https://github.com/charlottevedrines/MultiModal-SentimentAnalysis/assets/97196465/e49b547e-7c5b-44a5-8429-6a562d9bb9cd)

The [full report](Final_Report.pdf) written by all three collaborators is publicly available.
